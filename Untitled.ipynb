{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06582671-6314-4635-84ce-d6f0d53b3fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tutils.timg.draw_heatmap import draw_scatter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b66ee38b-131f-434b-b01a-5a0dc7af0180",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(10)\n",
    "y = np.arange(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5d8360b-9188-411a-8137-a8f47ab94e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Must be before importing matplotlib.pyplot or pylab!\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_scatter2(points, points2, fname=\"ttest.png\", c=\"red\", set_font=None, xlabel=\"x\", ylabel=\"y\"):\n",
    "    plt.ioff()  # Turn off interactive plotting off\n",
    "    if set_font is not None:\n",
    "        plt.rc('font', family='Times New Roman')\n",
    "    fig = plt.figure()\n",
    "    fig.suptitle('test 2*2 axes')\n",
    "    parent, tail = os.path.split(fname)\n",
    "    points = points.flatten()\n",
    "    points2 = points2.flatten()\n",
    "    plt.scatter(points, points2, c=c, label=\"???\")\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.savefig(fname)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb2749d7-3279-460a-94f9-012cf01064d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_scatter2(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7be9854-e65b-46bd-ab2a-352706ddbe61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2],\n",
      "         [ 3,  4,  5],\n",
      "         [ 6,  7,  8]],\n",
      "\n",
      "        [[ 9, 10, 11],\n",
      "         [12, 13, 14],\n",
      "         [15, 16, 17]],\n",
      "\n",
      "        [[18, 19, 20],\n",
      "         [21, 22, 23],\n",
      "         [24, 25, 26]]])\n",
      "torch.Size([1, 27, 3])\n",
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from typing import Tuple\n",
    "\n",
    "def unravel_index(\n",
    "    indices: torch.LongTensor,\n",
    "    shape: Tuple[int, ...],\n",
    ") -> torch.LongTensor:\n",
    "    r\"\"\"Converts flat indices into unraveled coordinates in a target shape.\n",
    "\n",
    "    This is a `torch` implementation of `numpy.unravel_index`.\n",
    "\n",
    "    Args:\n",
    "        indices: A tensor of (flat) indices, (*, N).\n",
    "        shape: The targeted shape, (D,).\n",
    "\n",
    "    Returns:\n",
    "        The unraveled coordinates, (*, N, D).\n",
    "    \"\"\"\n",
    "\n",
    "    coord = []\n",
    "\n",
    "    for dim in reversed(shape):\n",
    "        coord.append(indices % dim)\n",
    "        indices = indices // dim\n",
    "\n",
    "    coord = torch.stack(coord[::-1], dim=-1)\n",
    "\n",
    "    return coord\n",
    "\n",
    "# x = torch.rand(1, 120, 120)\n",
    "x = torch.arange(27).view(3,3,3)\n",
    "# indices = torch.topk(x, 1, dim=0)\n",
    "print(x)\n",
    "indices = unravel_index(x.view(1,-1), x.size())\n",
    "print(indices.size())\n",
    "# print(indices)\n",
    "print(x[0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5975e06-5dbf-4273-b83b-77fb0de70e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbb618d-66ab-4aa5-be7e-df86cd3427d4",
   "metadata": {},
   "source": [
    "Test configs to save list, and read list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b45799b1-695a-410e-8e6f-ecc714ac4cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': {'lr': 0.0001, 'decay': 0.002, 'moment': 0.5, 'tag': 'Train1', 'epoch': 500}, 'test': {'epoch': 200, 'tag': 'Test2'}, 'alist': [2, 3, 4]}\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import yamlloader\n",
    "import numpy as np\n",
    "\n",
    "with open(\"./conf.yaml\") as f:\n",
    "    config = yaml.load(f, Loader=yamlloader.ordereddict.CLoader)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ae061d4-ea61-4edb-aa33-c761f6a2c814",
   "metadata": {},
   "outputs": [],
   "source": [
    "alist = config['alist']\n",
    "alistt = np.array(config['alist'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "840c3f88-7a90-445d-96eb-bed4c5b6c798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(alist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9add855e-2ac8-450d-a96a-a8e28258766a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tmp.yml\", \"w\") as f:\n",
    "    yaml.dump(config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfde26a0-f847-4fcd-a34c-64ae6f44dabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa, bbb = (11, 22) if alist[0]>5 else (33,44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14f6fb72-5793-48cf-bd26-9d0a8e62611d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "aaa = torch.rand((1,16,5,5,3))\n",
    "ind = np.ones((1,1,5,5,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ce941be-8dec-4dd8-8f84-3b670d39ad5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import numpy as np\n",
    "import numpy as np\n",
    "final_cos = np.ones((50,50,12))\n",
    "ind = np.unravel_index(final_cos.argmax(), final_cos.shape)\n",
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3bd949ca-f0fb-4319-90f2-39da624b2ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a1 = np.random.random((32,32))\n",
    "a1 = np.arange(32*32).reshape((32,32))/32/32\n",
    "a2 = np.arange(32*32).reshape((32,32))/32/32 #np.random.random((32,32))\n",
    "a3 = np.arange(32*32).reshape((32,32))/32/32 # np.random.random((32,32))\n",
    "alist = [a1,a2,a3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "337dd726-ada1-48a8-80b9-a1a77c5a8c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 160)\n",
      "(32, 160)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKAAAAAgCAIAAAAaHeSiAAABBklEQVR4nO2UMQ6DMBAEfRKS3ZLP+HkoLw6l6dKgBDfocrG15lhXU6BhrUFIqI+ItOVt2+gH+qcYY3MpeRyeUkoisr7WcDjzY277MvpR/j1wqE9Kqe0F6Ef568DPEJaLXYD+c64DL9e7AP3nzF+0c7/knHsM/XAphX6gf+r3Mbph+IB/mIEZ+PbcSgjxM7BzZmDnzMDOmYGdMwM75z0wfMfgDB9gZgZWMXyAmRlYxfABZmZgFcMHmJmBVQwfYGYGVrHm4TH9DOycGdg5fwN3esfxXNo/SLBfuXtgNwwfYGMG1jJ8gI0ZWMvwATZmYC3DB9iYgbUMH2BjBtYyfICNGVjL8AE2fgMVSDxE5TZstgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=160x32 at 0x7FEBE0F96490>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from einops import rearrange\n",
    "\n",
    "def draw_heatmaps(heatmap: List[np.ndarray], pred: list = [], gts: list = [], fname=None):\n",
    "    \"\"\"\n",
    "        Draw Heatmap with Landmarks\n",
    "            pred: prediction (Red)    , only one prediction\n",
    "            GT:  Groud-truth (Green)  , only one gt\n",
    "    \"\"\"\n",
    "    row = len(heatmap)\n",
    "    assert len(heatmap[0].shape) == 2, f\"Got heatmap[0].shape {heatmap[0].shape}\"\n",
    "    height, width = heatmap[0].shape\n",
    "    heatmap_scale = (heatmap[-1] - np.min(heatmap[-1]))/(np.max(heatmap[-1]) - np.min(heatmap[-1]))\n",
    "    heatmap.append(heatmap_scale)\n",
    "    heatmap = np.concatenate(heatmap, axis=1)\n",
    "    print(heatmap.shape)\n",
    "    heatmap = np.clip(heatmap, 0, 1) * 255\n",
    "    heatmap = heatmap.astype(np.uint8)\n",
    "    print(heatmap.shape)\n",
    "    imgs = Image.fromarray(heatmap).convert('RGB')\n",
    "    draw = ImageDraw.Draw(imgs)\n",
    "    red = (255, 0, 0)\n",
    "    green = (0, 255, 0)\n",
    "    if pred != [] and gts != []:\n",
    "        for i in range(row+1):\n",
    "            draw.rectangle((pred[0] + i * width - 2, pred[1] - 2, pred[0] + i * width + 2, pred[1] + 2), fill=red)\n",
    "            draw.rectangle((gts[0] + i * width - 2, gts[1] - 2, gts[0] + i * width + 2, gts[1] + 2), fill=green)\n",
    "        draw.line([tuple(pred), tuple(gts)], fill='green', width=0)\n",
    "    if fname is None:\n",
    "        return imgs\n",
    "    else:\n",
    "        imgs.save(fname)\n",
    "        \n",
    "heatmaps = alist\n",
    "draw_heatmaps(alist, [4,4], [4,4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "48e5ace9-81b9-47b1-925c-a8701cbcf419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FEBE0FCAA60>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from einops import rearrange\n",
    "\n",
    "def draw_landmarks_on_image(img: np.ndarray, preds: List[list], gts: List[list], fname=None,\n",
    "              ratio: int = 0.01, draw_line: bool = True):\n",
    "    \"\"\"\n",
    "        Here we denote:\n",
    "        preds: red  [[x,y,z], .....]\n",
    "        gts: green, [[x,y,z], .....]\n",
    "    \"\"\"\n",
    "#     assert len(img.shape) == 3, f\"Got shape {img.shape}\"\n",
    "    h, w = img.shape[-2], img.shape[-1]\n",
    "    radius_base = int(min(h, w) * ratio)\n",
    "\n",
    "    red = (255, 0, 0)\n",
    "    green = (0, 255, 0)\n",
    "\n",
    "    img = Image.fromarray(img.astype(np.uint8)).convert('RGB')\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    for i, landmark in enumerate(preds):\n",
    "        gt = gts[i]\n",
    "        radius = radius_base\n",
    "        draw.rectangle((gt[0] - radius, gt[1] - radius, \\\n",
    "                        gt[0] + radius, gt[1] + radius), fill=green)\n",
    "        draw.rectangle((landmark[0] - radius, landmark[1] - radius, \\\n",
    "                        landmark[0] + radius, landmark[1] + radius), fill=red)\n",
    "        if draw_line:\n",
    "            draw.line([tuple(landmark), (gt[0], gt[1])], fill='green', width=0)\n",
    "    if fname is None:\n",
    "        return img\n",
    "    else:\n",
    "        img.save(fname)\n",
    "\n",
    "size = 512\n",
    "a1 = np.arange(size*size).reshape((size,size))/size/size*255\n",
    "draw_landmarks_on_image(a1, [[2,2]], [[2,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "36772fda-6987-40bf-b717-69f05d8377e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'data', 'quanquan', 'oneshot', 'runs2', '']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '/data/quanquan/oneshot/runs2/'\n",
    "s.split('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07566f8b-49b2-4cd8-9ba8-5f14a57fc0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def build_gaussian_layer(mean, standard_deviation, step=1, len=8, sharpness=0.2):\n",
    "    \"\"\"\n",
    "    copy from blog.csdn.net\n",
    "    \"\"\"\n",
    "    # scaled_size = int(len / sharpness)\n",
    "    scaled_size = len\n",
    "    center_point = (scaled_size, scaled_size)\n",
    "    x = np.arange(-scaled_size + 1, scaled_size, step) * (sharpness**2)\n",
    "    y = np.arange(-scaled_size + 1, scaled_size, step) * (sharpness**2)\n",
    "    x, y = np.meshgrid(x, y)\n",
    "    z = np.exp(-((y - mean) ** 2 + (x - mean) ** 2) / (2 * (standard_deviation ** 2)))\n",
    "    z = z / (np.sqrt(2 * np.pi) * standard_deviation)\n",
    "    return (x, y, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60acb84f-2713-48e2-83cf-8974e43ec7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import yamlloader\n",
    "from collections import OrderedDict\n",
    "\n",
    "def ordereddict_to_dict(d):\n",
    "    if type(d) not in [OrderedDict, dict]:\n",
    "        return d\n",
    "    for k, v in d.items():\n",
    "        if type(v) == OrderedDict:\n",
    "            v = ordereddict_to_dict(v)\n",
    "            d[k] = dict(v)\n",
    "        elif type(v) == list:\n",
    "            d[k] = ordereddict_to_dict(v)\n",
    "        elif type(v) == dict:\n",
    "            d[k] = ordereddict_to_dict(v)\n",
    "    return d\n",
    "\n",
    "with open('./conf.yaml', 'r') as f:\n",
    "    config = yaml.load(f, Loader=yamlloader.ordereddict.CLoader)\n",
    "\n",
    "config[\"new_dict\"] = {\"aa\":1, \"bb\":2}\n",
    "config['new_dict2'] = OrderedDict()\n",
    "config['new_dict2']['test'] = 'test'\n",
    "config['new_dict2']['test2'] = OrderedDict(aa=1, bad=2)\n",
    "\n",
    "\n",
    "# for key, value in config.items():\n",
    "#     if type(value) == OrderedDict:\n",
    "#         config[key] = dict(value)\n",
    "\n",
    "with open('./tmp.yaml', 'w') as f:\n",
    "    yaml.dump(ordereddict_to_dict(config), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "efe79522-2b99-48c7-8a5f-258279f9d4b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3205, 0.4282, 0.2513])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import  torch.nn.functional  as F\n",
    "import torch\n",
    "softmax = torch.nn.Softmax(dim=0)\n",
    "ass = torch.rand((3))\n",
    "softmax(ass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ccf5052-6bdf-470c-ae53-dce37c9b684a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "Radius = 32\n",
    "mask = torch.zeros(2*Radius, 2*Radius, dtype=torch.float)\n",
    "guassian_mask = torch.zeros(2*Radius, 2*Radius, dtype=torch.float)\n",
    "for i in range(2*Radius):\n",
    "    for j in range(2*Radius):\n",
    "        distance = np.linalg.norm([i+1 - Radius, j+1 - Radius])\n",
    "        if distance < Radius:\n",
    "            mask[i][j] = 1\n",
    "save_image(mask, \"tmp.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3aa5281b-68c6-476d-b2cb-0b0a69ea2aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "Radius = 32\n",
    "mask = torch.zeros(2*Radius, 2*Radius, 2*Radius, dtype=torch.float)\n",
    "guassian_mask = torch.zeros(2*Radius, 2*Radius, 2*Radius, dtype=torch.float)\n",
    "for i in range(2*Radius):\n",
    "    for j in range(2*Radius):\n",
    "        for k in range(2*Radius):\n",
    "            distance = np.linalg.norm([i+1 - Radius, j+1 - Radius, k+1 - Radius])\n",
    "            if distance < Radius:\n",
    "                mask[i][j][k] = 1\n",
    "\n",
    "\n",
    "save_image(mask[:,Radius//2, :], \"tmp.png\")\n",
    "print(\"over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee79eeba-57cb-42c4-99c6-88c2c62d580e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from einops import repeat, rearrange\n",
    "HYPER_PARAM_R = 128\n",
    "msefn = torch.nn.MSELoss()\n",
    "def distance_loss_batch(vectors_image, vector_temp, pos_temp):\n",
    "    assert vectors_image.size()[1:] == (3, 128, 128, 40)\n",
    "    assert vector_temp.size()[-1] == 3\n",
    "    assert pos_temp.size()[-1] == 3\n",
    "    # assert\n",
    "    vectors_image = rearrange(vectors_image, \"b c h w d -> b c (h w d)\")\n",
    "    pos_temp = repeat(pos_temp, \"b c -> b c n\", n=vectors_image.size(-1))\n",
    "\n",
    "    d2 = torch.tanh(vectors_image - repeat(vector_temp, \"b c -> b c n\", n=vectors_image.size(-1))) * HYPER_PARAM_R\n",
    "    pos = np.array(np.unravel_index(np.arange(128 * 128 * 40), (128, 128, 40))).transpose((1, 0))\n",
    "    pos = torch.Tensor(pos)\n",
    "    pos = repeat(pos, \"n c -> b c n\", b=vectors_image.size(0))\n",
    "    d1 = pos - pos_temp\n",
    "    loss = msefn(d1, d2)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82db0474-b32a-4424-96f0-7cf27ef8bd61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5588.3281)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_img = torch.rand((2,3,128,128,40))\n",
    "v_tmp = torch.rand((2,3))\n",
    "pos_tmp = torch.rand((2,3))*40\n",
    "pos_tmp = pos_tmp.int()\n",
    "loss = distance_loss_batch(v_img, v_tmp, pos_tmp)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0daaa642-ad20-4ad0-a548-7b8161d14d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_tmp.size()[-1] == 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15a5fb17-f83e-4feb-9a48-2c875696e17d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3,  9, 39],\n",
       "        [ 8, 26, 11]], dtype=torch.int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5acb7c8-240b-4c93-aab8-a8c7bc6ff88f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5.5000, 17.5000, 25.0000])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tmp.permute(1,0).float().mean(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d3e1ed3-8de9-436c-b869-a63ca1fc207b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'config': 4312}\n",
      "config {'config': 4312}\n",
      "a 333\n"
     ]
    }
   ],
   "source": [
    "def tttest(a, **kwargs):\n",
    "    print(kwargs['config'])\n",
    "    for key, value in kwargs.items():\n",
    "        print(key, value)\n",
    "    print(\"a\", a)\n",
    "    \n",
    "tttest(a=333, config={\"config\":4312})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9aad0bda-a95d-4055-be60-bb516a6ef18c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 4, 4, 4]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "aa = np.arange(0,20).tolist()\n",
    "# bb = aa - np.array([0,1,2,3,4]).tolist()\n",
    "bb = aa[0:0] + [4,4,4,4]\n",
    "bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af44256-38a9-4664-a1f6-2ddf5cbd7ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "aa = torch.rand((4,3))\n",
    "bb = np.array((128, 128, 40))\n",
    "cc = aa*bb\n",
    "print(aa)\n",
    "print(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7026775e-884e-4a1b-a7d8-5ada96a3c121",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "vector = torch.rand((1,64,1,1))\n",
    "print(vector)\n",
    "normed = torch.norm(vector, dim=2, keep_dim=True)\n",
    "print(normed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d191a2-8b06-4861-9480-25efba30f303",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
