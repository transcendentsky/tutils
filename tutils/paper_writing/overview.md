# Writing Framework

## Intro:
background: 
    existing methods -> unsolved problem -> our idea -> our method
    

# Experiment

- Dataset: info, 
- Metrics: 
- Implemetation details: implemented by Pytorch, accelarated by an NVIDIA RTX3090 GPU, 

- optimized by `Adam optimizer` for `3500 epochs` with `learning rate 0.001` decayed by `half` every `500 epochs`, which take `6 hours` to converge

- other hyper-parameters: embedding length $L$ is set to be 16, and $\alpha$, 

- `Consequently`, most of the landmarks ...

- According to Table 2, all of the experimental results fluctuate slightly when changing the two parameters. 

- On the contrary, xx may tend to overfit 

- 